<<<<<<< HEAD
# ðŸ“„ Multi-Utility LangGraph PDF Chatbot

A **Streamlit-based conversational AI application** powered by **LangGraph**, **Groq LLM**, and **FAISS**, supporting **PDF-based RAG**, **tool usage**, and **multi-threaded persistent chat history**.

---

## ðŸš€ Features

### ðŸ”¹ Conversational AI
- Uses **Groq-hosted LLM (`openai/gpt-oss-20b`)**
- Maintains **conversation memory** per chat thread
- Streams responses token-by-token for real-time UX

### ðŸ”¹ PDF Question Answering (RAG)
- Upload a PDF per chat thread
- Documents are:
  - Loaded with `PyPDFLoader`
  - Chunked using `RecursiveCharacterTextSplitter`
  - Embedded via **HuggingFace MiniLM**
  - Stored in **FAISS**
- Context is retrieved **only when required** using a dedicated `rag_tool`

### ðŸ”¹ Built-in Tools
The assistant can autonomously decide to use:
- ðŸ” DuckDuckGo Search (current information)
- ðŸ§® Calculator (add, subtract, multiply, divide)
- ðŸŒ¦ Weather lookup
- ðŸ“ˆ Stock price lookup (Alpha Vantage)
- â° Current date & time
- ðŸ“„ PDF RAG tool (thread-aware)

> Tool outputs are **never shown directly** to the user â€” only final assistant responses.

---

## ðŸ§  Architecture Overview

```
User (Streamlit UI)
   â†“
LangGraph StateGraph
   â”œâ”€â”€ chat_node (LLM reasoning)
   â”œâ”€â”€ ToolNode (tools execution)
   â””â”€â”€ SQLite Checkpointer (state persistence)
```

PDF Flow:
```
PDF â†’ PyPDFLoader â†’ Chunking â†’ Embeddings â†’ FAISS â†’ rag_tool
```

---

## ðŸ—‚ Project Structure

```
.
â”œâ”€â”€ backend_rag_chatbot.py   # LangGraph backend logic
â”œâ”€â”€ app.py                  # Streamlit frontend
â”œâ”€â”€ chatbot.db              # SQLite checkpoint database
â”œâ”€â”€ .env                    # API keys
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Tech Stack

### Backend
- LangGraph
- LangChain
- Groq LLM
- FAISS
- HuggingFace Embeddings
- SQLite (checkpointing)

### Frontend
- Streamlit
- Streaming chat UI
- Session-based thread management

---

## ðŸ” Environment Variables

Create a `.env` file:

```env
groq_api=YOUR_GROQ_API_KEY
WEATHERSTACK_API_KEY=YOUR_WEATHERSTACK_KEY
ALPHAVANTAGE_API_KEY=YOUR_ALPHA_VANTAGE_KEY
```

---

## â–¶ï¸ Running the App

```bash
streamlit run app.py
```

---

## ðŸ§ª How It Works

1. User starts or selects a chat thread
2. (Optional) Uploads a PDF
3. User sends a message
4. LangGraph decides whether to call a tool
5. RAG is used **only** for PDF-related questions
6. Responses stream live to the UI
7. State and metadata persist in SQLite

---

## ðŸ§µ Thread Persistence

- Each thread stores:
  - Messages
  - Title
  - Creation timestamp
- Switching threads restores the full conversation
- PDFs are isolated **per thread**

---

## ðŸ›¡ Design Constraints

- Assistant must **either respond OR call one tool**
- Tool outputs are internal only
- RAG is strictly limited to uploaded PDFs
- Context window capped to avoid overflow

---

## ðŸ Summary

This project demonstrates a **production-grade LangGraph chatbot** with:
- Multi-threaded memory
- Tool-augmented reasoning
- Thread-aware RAG
- Streaming UI
- Persistent state

Ideal for real-world conversational AI systems â€” not just demos.

=======
# multi-tool-rag-chatbot
>>>>>>> eb6031ffed5bcfe5935e8344f32c5aa626e5633a
